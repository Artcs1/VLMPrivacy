<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="C2G2: Controllable Co-speech Gesture Generation with Latent diffusion models">
  <meta name="keywords" content="C2G2, latent_diffusion, Gesture_generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>C2G2: Controllable Co-speech Gesture Generation with Latent diffusion models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">C2G2: Controllable Co-speech Gesture Generation</h1>
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com">Longbin Ji</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Pengfei Wei</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Ren Yi</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Jinglin Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Chen Zhang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Xiang.Yin</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Xi'an Jiaotong Liverpool University,</span>
            <span class="author-block"><sup>2</sup>Bytedance Research</span>
          </div> -->

          <!-- <div class="column has-text-centered"> -->
            <!-- <div class="publication-links"> -->
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
<!--               <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/C2G2-Gesture/C2G2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            <!-- </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present the first method capable of controlling the speaker identity and allowing movement editing with high-quality co-speech generation.
          </p>
          <p>
            Co-speech gesture generation is crucial for automatic digital avatar animation. 
However, existing methods suffer from issues such as unstable training and temporal inconsistency, particularly in generating high-fidelity and comprehensive gestures. 
Additionally, these methods lack effective control over speaker identity and temporal editing of the generated gestures.
          </p>
          <p>
            
Focusing on capturing temporal latent information and applying practical controlling, we propose a Controllable Co-speech Gesture Generation framework, named C2G2.
Specifically, we propose a two-stage temporal dependency enhancement strategy motivated by latent diffusion models.
We further introduce two key features to C2G2, namely a speaker-specific decoder to generate speaker-related real-length skeletons and a repainting strategy for flexible gesture generation/editing. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Model</h2>
        <div style="width:850px;display:block;margin:0 auto">
          <img src="./static/images/new_c2g2.jpeg"
               class="interpolation-image"
               alt="Interpolate start reference image."/>
          <p>C2G2: Model Structure</p>
        </div>
      </div>
    </div> 
  </div>
</section>

<section class="section">
  <div class="columns is-centered has-text-centered">
    <h2 class="title is-3">Short clips</h2>
  </div>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_gt_4.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> Ground Truth
          </h4>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_s2g2_4.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> C2G2
          </h4>
      </div>
    </div>

    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_diffgesture_4.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> Diffgesture
          </h4>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_ha2g_000_4.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> HA2G
          </h4>
        </div>
      </div>
    </div>

    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_gt_8.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> Ground Truth
          </h4>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_s2g2_8.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> C2G2
          </h4>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_diffgesture_8.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> Diffgesture
          </h4>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/short_ha2g_000_8.mp4"
                    type="video/mp4">
          </video>
          <h4 class="subtitle has-text-centered">
            <span class="dnerf"> HA2G
          </h4>
        </div>
        
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="hero-body">
    <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/short_gt_8.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> Ground Truth
            </h4>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/short_s2g2_8.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> C2G2
            </h4>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/short_diffgesture_8.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> Diffgesture
            </h4>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/short_ha2g_000_8.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> HA2G
            </h4>
          </div>
          
        </div>
    </div>

    
  </div>
</section> -->

<section class="section">
  <div class="columns is-centered has-text-centered">
    <h2 class="title is-3">Long clips</h2>
  </div>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/long_gt_2.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> Ground Truth
            </h4>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/long_s2g2_2.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> C2G2
            </h4>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/long_diffgesture_2.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> Diffgesture
            </h4>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/long_ha2g_002_0.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> HA2G
            </h4>
          </div>
  
      </div>
    </div>
    
  </div>
</section>

<section class="section">
  <div class="columns is-centered has-text-centered">
    <h2 class="title is-3">Middle clips (In-betweening Edit)</h2>
  </div>
  <p></p>
  <div class="columns is-centered has-text-centered">
    <h4> First 4 frames is given as pre condition, 150-173 is ground truth; 144-150 uses gt for repaint sampling</h4>
  </div>
  <div class="hero-body">

    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/edited_gt_1.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> Ground Truth
            </h4>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/edited_s2g2_1.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> C2G2
            </h4>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/edited_diffgesture_1.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> Diffgesture
            </h4>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/c2_videos/edited_ha2g_001_0.mp4"
                      type="video/mp4">
            </video>
            <h4 class="subtitle has-text-centered">
              <span class="dnerf"> HA2G
            </h4>
          </div>
        
        </div>
      </div>
    </div>
    
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">In-betweening Editing</h2>
          <p>
            Using C2G2 to enable In-betweening generation task, last few frames (after 144 frames) is edited movements.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/c2_videos/end_edit.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">In-the-Middle Editing</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Using C2G2, you could generate high-fidelity gestures with in-the-middle movement editing without mismatching (frames from 70-94 is edited).
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/c2_videos/middle_edit.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Speaker-Related Generation</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">Speaker 1</h3>
        <div class="content has-text-justified">
          <p>
            Visual effects of localize the generated results into actual frames. We can generate long-term reliable results with 4 pre-frames and one random frame conditioning.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/jack.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video"
                   controls
                   muted
                   preload
                   playsinline
                   width="40%">
              <source src="./static/c2_videos/jack.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <br/>

        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- Interpolating. -->
        <h3 class="title is-4">Speaker 2</h3>
        <div class="content has-text-justified">
          <p>
            Visual effects of localize the generated results into actual frames. We can generate long-term reliable results with 4 pre-frames and one random frame conditioning.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/lucy.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video"
                   controls
                   muted
                   preload
                   playsinline
                   width="40%">
              <source src="./static/c2_videos/lucy.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <h3 class="title is-4">Speaker 3</h3>
        <div class="content has-text-justified">
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/lisa.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video"
                   controls
                   muted
                   preload
                   playsinline
                   width="40%">
              <source src="./static/c2_videos/lisa.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            Our work is mainly based on Diffgesture and Taming Transformer. Thanks the authors for their great contributions and inspiring ideas.
          </p>
          <p>
            Also, There's a lot of excellent work that was introduced around the same time as ours for co-speech generation.
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div> -->
    </div>
  </div>
</footer>

</body>
</html>
